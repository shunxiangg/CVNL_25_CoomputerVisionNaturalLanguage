# -*- coding: utf-8 -*-
"""Week07_PerformanceMetrics.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rWMPZGZcpKQGoAqNSdhgnt2EOdoPgQiI
"""

# If needed, install packages (uncomment in a notebook)
# !pip install numpy scikit-learn torch

import numpy as np
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score,
    confusion_matrix, roc_curve, roc_auc_score,
    mean_squared_error, mean_absolute_error
)

import torch
import torch.nn as nn

# 1 = positive class, 0 = negative class

y_true = np.array([1, 0, 1, 1, 0, 0, 1, 0])
y_pred = np.array([1, 0, 1, 0, 0, 1, 1, 0])  # model predictions (labels)

acc = accuracy_score(y_true, y_pred)
prec = precision_score(y_true, y_pred, pos_label=1)
rec = recall_score(y_true, y_pred, pos_label=1)
f1 = f1_score(y_true, y_pred, pos_label=1)

# Compute FPR explicitly from the confusion matrix
tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()
fpr = fp / (fp + tn)

print("Accuracy:", acc)
print("Precision:", prec)
print("Recall:", rec)
print("F1-score:", f1)
print("False Positive Rate (FPR):", fpr)

cm = confusion_matrix(y_true, y_pred)
print("Confusion matrix:\n", cm)

y_true = np.array([1, 0, 1, 1, 0, 0, 1, 0])
# model's probability that the class is 1
y_scores = np.array([0.9, 0.2, 0.8, 0.4, 0.3, 0.7, 0.95, 0.1])

fpr, tpr, thresholds = roc_curve(y_true, y_scores, pos_label=1)

print("FPR:", fpr)
print("TPR:", tpr)
print("Thresholds:", thresholds)

auc_value = roc_auc_score(y_true, y_scores)
print("AUC:", auc_value)

import matplotlib.pyplot as plt

plt.plot(fpr, tpr, marker='.')
plt.plot([0, 1], [0, 1], linestyle='--')  # random baseline
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.show()

y_true_reg = np.array([3.0, 5.0, 2.5, 7.0])
y_pred_reg = np.array([2.5, 5.0, 4.0, 6.0])

mse = mean_squared_error(y_true_reg, y_pred_reg)
mae = mean_absolute_error(y_true_reg, y_pred_reg)
rmse = np.sqrt(mse)

print("MSE:", mse)
print("MAE:", mae)
print("RMSE:", rmse)

y_true_reg_t = torch.tensor([3.0, 5.0, 2.5, 7.0])
y_pred_reg_t = torch.tensor([2.5, 5.0, 4.0, 6.0])

mse_loss_fn = nn.MSELoss()
l1_loss_fn = nn.L1Loss()

mse_torch = mse_loss_fn(y_pred_reg_t, y_true_reg_t)
mae_torch = l1_loss_fn(y_pred_reg_t, y_true_reg_t)
rmse_torch = torch.sqrt(mse_torch)

print("PyTorch MSE:", mse_torch.item())
print("PyTorch MAE:", mae_torch.item())
print("PyTorch RMSE:", rmse_torch.item())

# Suppose we have 3 classes (0, 1, 2) and a batch of 3 samples
logits = torch.tensor([
    [2.0, 1.0, 0.1],  # sample 1 raw scores
    [0.5, 2.5, 0.3],  # sample 2
    [0.1, 0.2, 2.0]   # sample 3
], dtype=torch.float32)

targets = torch.tensor([0, 1, 2])  # true class indices

ce_loss_fn = nn.CrossEntropyLoss()
ce_loss = ce_loss_fn(logits, targets)

print("Cross-entropy loss (PyTorch):", ce_loss.item())