# -*- coding: utf-8 -*-
"""Week02_Exercises.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LGjfKsTQdmm7aMPcnv6EX3seQKbFjfNm

**IntroToPyTorchII Exercises**

Q1
Write a series of for loops that compute the average value in torch_tensor3d (refer to torch_tensor3d in IntroToPyTorch Activity)
"""

import torch
torch_tensor3d = torch.Tensor([
[
[ 1, 2, 3],
[ 4, 5, 6],
],
[
[ 7, 8, 9],
[10, 11, 12],
],
[
[13, 14, 15],
[16, 17, 18],
],
[
[19, 20, 21],
[22, 23, 24],
]
])

total = 0
count = 0

for i in range(torch_tensor3d.size(0)):
    for j in range(torch_tensor3d.size(1)):
        for k in range(torch_tensor3d.size(2)):
            total += torch_tensor3d[i][j][k].item()
            count += 1

average = total / count

print(f"Average value in torch_tensor3d is: {average}")

#Alternative answer
total = 0

x,y,z = torch_tensor3d.shape
for i in range(x):
    for j in range(y):
        for k in range(z):
            total += torch_tensor3d[i][j][k]

average = total / (x*y*z)

print(f"Average value in torch_tensor3d is: {average}")

"""Q2. For every power of 2 (i.e., 2 to power of i or 2i ) up to 2 to power of 11, create a random matrix X ∈ R2i;2i (i.e., X.shape should give (2i, 2**i)). Time how long it takes to compute XX (i.e., X @ X) on a CPU and on a GPU, and plot the speedup. For what matrix sizes is the CPU faster than the GPU?"""

import torch
import time
import seaborn as sns
import matplotlib.pyplot as plt

device = torch.device("cuda")

cpu_times = []
gpu_times = []
matrix_sizes = []
max_power = 11

for i in range(1, max_power + 1):
  size = 2**i
  matrix_sizes.append(size)

  X = torch.randn(size, size)

  # Measure CPU time
  start_cpu = time.time()
  X_cpu = X @ X  # Matrix multiplication on CPU
  cpu_times.append(time.time() - start_cpu)

  # GPU Calculation
  X_gpu = X.to(device) # Moves the data to CPU or GPU depending on device
  start_gpu = time.time()
  X_gpu_result = X_gpu @ X_gpu  # Matrix multiplication on GPU
  gpu_times.append(time.time() - start_gpu)

 # Calculate speedup in an iterator of tuples
 # Speedup is computed as the ratio of CPU time to GPU time.
speedup = [cpu / gpu for cpu, gpu in zip(cpu_times, gpu_times)]

# Plot the results
plt.figure(figsize=(12, 6))

# Plot CPU and GPU times
# figure with 1 row and 2 columns (2 graphs side by side), 1st plot
plt.subplot(1, 2, 1)
plt.plot(matrix_sizes, cpu_times, label="CPU Time", marker="o")
plt.plot(matrix_sizes, gpu_times, label="GPU Time", marker="o")
plt.xscale("log")
plt.yscale("log")
plt.xlabel("Matrix Size (2^i)")
plt.ylabel("Time (s)")
plt.title("CPU vs GPU Time for Matrix Multiplication")
plt.legend()

# Plot speedup
# figure with 1 row and 2 columns (2 graphs side by side), 2nd plot
plt.subplot(1, 2, 2)
plt.plot(matrix_sizes, speedup, label="Speedup (CPU/GPU)", marker="o", color="purple")
plt.xscale("log")
plt.xlabel("Matrix Size (2^i)")
plt.ylabel("Speedup")
plt.title("Speedup of GPU over CPU")
#draw a horizontal line
plt.axhline(y=1, color="red", linestyle="--", label="CPU=GPU")
plt.legend()

plt.tight_layout()
plt.show()

# Identify when CPU is faster
for i, size in enumerate(matrix_sizes):
    if cpu_times[i] < gpu_times[i]:
        print(f"CPU is faster than GPU for matrix size: {size}x{size}")
    else:
        print(f"GPU is faster than CPU for matrix size: {size}x{size}")

"""Observations:

Small matrix sizes: CPU is often faster due to the overhead of transferring data to/from the GPU and GPU kernel launch times.

Large matrix sizes: GPU becomes significantly faster as its parallel processing renders higher efficiency over data transfer and GPU launch times.

Q3.
We used PyTorch to find the numeric solution to f(x) = (x - 2)2. Write code that finds the solution to f(x) = sin(x - 2) · (x + 2)2 +√(| cos(x)|). What answer do you get?
"""

import torch

# Define the function f(x)
def f(x):
    return torch.sin(x - 2) * (x + 2)**2 + torch.sqrt(torch.abs(torch.cos(x)))

x = torch.tensor([-3.5], requires_grad=True)
x_cur = x.clone()
x_prev = x_cur*100

#threshold for the current and previous to be close enough
#before stop.
epsilon = 1e-5
eta = 0.1 #learning rate
while torch.linalg.norm(x_cur-x_prev) > epsilon:
  x_prev = x_cur.clone() #so that x_prev and x_cur don't point to same object.
  value = f(x) #These next few lines computethe function, gradient, and update.

  value.backward()
  x.data -= eta * x.grad
  x.grad.zero_() #Zeros out the old gradient,

  x_cur = x.data #Accesses .data to avoid autograd mechanics.

print(x_cur)

"""Q4.
Write a new function that takes two inputs, x and y, where
f(x; y) = exp(sin(x)2) /(x - y)2 + (x - y)2

Use an Optimizer with initial parameter values of x = 0.2 and y = 10. What do
they converge to?

"""

import torch

# Define the function f(x, y)
def f(args):
    x, y = args
    return torch.exp(torch.sin(x)**2) / (x - y)**2 + (x - y)**2

param = torch.nn.Parameter(torch.tensor([0.2, 10]), requires_grad=True)
eta = 0.1 #learning rate
optimizer = torch.optim.SGD([param], lr=eta)

for epoch in range(60):
  optimizer.zero_grad()
  loss = f(param)
  loss.backward() # The gradients with respect to x, y computed and updated in each step.
  optimizer.step() #x.data -= eta * x.grad

print(param.data)