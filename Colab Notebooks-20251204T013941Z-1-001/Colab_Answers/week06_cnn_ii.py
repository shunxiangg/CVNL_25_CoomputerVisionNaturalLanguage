# -*- coding: utf-8 -*-
"""Week06_CNN_II.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LGILbXrpyRJDNpb0OF7Y-o5UUpaW3MK_
"""

from google.colab import drive
drive.mount('/content/drive')

import sys
sys.path.append('/content/drive/My Drive/Colab Notebooks/Week06')

import torch
import torch.nn as nn
import torch.nn.functional as F


from torch.utils.data import Dataset, DataLoader

from tqdm.autonotebook import tqdm

import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from matplotlib.pyplot import imshow

import pandas as pd

from sklearn.metrics import accuracy_score

import time
from idlmam import *

import torchvision
from torchvision import transforms
from scipy.signal import convolve

mnist_data_train = torchvision.datasets.MNIST("./data", train=True,\
                                        download=True, \
                                        transform=transforms.ToTensor())

mnist_data_test = torchvision.datasets.MNIST("./data", train=False,\
                                   download=True, \
                                   transform=transforms.ToTensor())

x_example, y_example = mnist_data_train[0]

img_indx = 0
img, correct_class = mnist_data_train[img_indx]
img = img[0,:]
img_lr = np.roll(np.roll(img, 1, axis=1), 1, axis=0) #Moves to the lower right
img_ul = np.roll(np.roll(img, -1, axis=1), -1, axis=0) #then upper left

f, axarr = plt.subplots(1,3) #Plots the images
axarr[0].imshow(img, cmap='gray')
axarr[1].imshow(img_lr, cmap='gray')
axarr[2].imshow(img_ul, cmap='gray')
plt.show()

if torch.cuda.is_available():
  device = torch.device("cuda")
else:
  device = torch.device("cpu")

B = 32
mnist_train_loader = DataLoader(mnist_data_train, batch_size=B, shuffle=True)
mnist_test_loader = DataLoader(mnist_data_test, batch_size=B)

#We use the number of values in the input
#to help determine the size of subsequent layers:
#28 * 28 images.
D = 28*28

#No of channels in input
C = 1

classes = 10

filters = 16

#Size of Kernel
K = 3

#For comparison, letâ€™s define a linear model
#of similar complexity.
model_linear = nn.Sequential(
  nn.Flatten(), # (B, C, W, H) -> (B, C*W*H) = (B,D)
  nn.Linear(D, 256),
  nn.Tanh(),
  nn.Linear(256, classes),
)

#Simple convolutional network.
#Conv2d follows the pattern
#Conv2d(No of input channels,
#filtersoutput-channels, filter-size).

model_cnn = nn.Sequential(
  nn.Conv2d(C, filters, K, padding=K//2), # x convolve with G
  #Activation functions
  #work on any size tensor.
  nn.Tanh(),
  #Converts from (B, C, W, H) ->(B, D)
  #so we can use a Linear layer.
  nn.Flatten(),
  nn.Linear(filters*D, classes),
)

loss_func = nn.CrossEntropyLoss()

cnn_results = train_simple_network(model_cnn, loss_func,\
                      mnist_train_loader, test_loader=mnist_test_loader,\
                        score_funcs={'Accuracy': accuracy_score}, \
                        device=device, epochs=20)

#eval mode since we are not training
model = model_cnn.cpu().eval()

def pred(model, img):
    with torch.no_grad():#Always turn off gradients when evaluating

        w, h = img.shape #Finds the width/height of the image
        if not isinstance(img, torch.Tensor):
            img = torch.tensor(img) #To make sure it works for both NumPy and PyTorch Tensor

        x = img.reshape(1,-1,w,h)#reshape it as (B, C, W, H)
        logits = model(x) #Get the logits
        y_hat = F.softmax(logits, dim=1)#Turn into probabilities
    return y_hat.numpy().flatten()#convert prediction to numpy array.

img_pred = pred(model, img)
img_lr_pred = pred(model, img_lr)
img_ul_pred = pred(model, img_ul)

print("Org Img Class {} Prob:         ".format(correct_class) , \
      img_pred[correct_class])
print("Lower Right Img Class {} Prob: ".format(correct_class) , \
      img_lr_pred[correct_class])
print("Upper Left Img Class {} Prob:   ".format(correct_class) , \
      img_ul_pred[correct_class])

model_cnn_pool = nn.Sequential(
  nn.Conv2d(C, filters, 3, padding=3//2),
  nn.Tanh(),
  nn.Conv2d(filters, filters, 3, padding=3//2),
  nn.Tanh(),
  nn.Conv2d(filters, filters, 3, padding=3//2),
  nn.Tanh(),
  nn.MaxPool2d(2),
  nn.Conv2d(filters, 2*filters, 3, padding=3//2),
  nn.Tanh(),
  nn.Conv2d(2*filters, 2*filters, 3, padding=3//2),
  nn.Tanh(),
  nn.Conv2d(2*filters, 2*filters, 3, padding=3//2),
  nn.Tanh(),
  nn.MaxPool2d(2),

  nn.Flatten(),
  #Why did we reduce the number of units into the Linear layer by a factor
  #of 4 to power 2? Because pooling a 2x2 grid down to one value means we go from
  #4 values, down to 1, and we did this two times.
  nn.Linear(2*filters*D//(4**2), classes),
)

loss_func = nn.CrossEntropyLoss()

cnn_results_with_pool = train_simple_network(model_cnn_pool, loss_func, \
                                             mnist_train_loader, \
                                             test_loader=mnist_test_loader, \
                                             score_funcs={'Accuracy': accuracy_score}, \
                                             device=device, epochs=20)

model = model_cnn_pool.cpu().eval()
img_pred = pred(model, img)
img_lr_pred = pred(model, img_lr)
img_ul_pred = pred(model, img_ul)

print("Org Img Class {} Prob:         ".format(correct_class) , img_pred[correct_class])
print("Lower Right Img Class {} Prob: ".format(correct_class) , img_lr_pred[correct_class])
print("Uper Left Img Class {} Prob:   ".format(correct_class) , img_ul_pred[correct_class])

sns.lineplot(x='epoch', y='test Accuracy', data=cnn_results, label='Simple CNN')
sns.lineplot(x='epoch', y='test Accuracy', data=cnn_results_with_pool, label='CNN w/ Max Pooling')

#Built-in transformations, given some large values to make impact more obvious.
sample_transforms = {
    "Rotation" : transforms.RandomAffine(degrees=45),
    "Translation" : transforms.RandomAffine(degrees=0, translate=(0.1,0.1)),
    "Shear": transforms.RandomAffine(degrees=0, shear=45),
    "RandomCrop" : transforms.RandomCrop((20,20)),
    "Horizontal Flip" : transforms.RandomHorizontalFlip(p=1.0),
    "Vertical Flip": transforms.RandomVerticalFlip(p=1.0),
    "Perspective": transforms.RandomPerspective(p=1.0),
    "ColorJitter" : transforms.ColorJitter(brightness=0.9, contrast=0.9)
}
#Convert the Tensor image back to a PIL image using a transform
pil_img = transforms.ToPILImage()(img)

#Plot a random application of each transform
f, axarr = plt.subplots(2,4)
for count, (name, t) in enumerate(sample_transforms.items()):
    row = count % 4
    col = count // 4
    axarr[col,row].imshow(t(pil_img), cmap='gray')
    axarr[col,row].set_title(name)
plt.show()

train_transform = transforms.Compose([
    transforms.RandomAffine(degrees=5, translate=(0.05, 0.05), scale=(0.98, 1.02)),
    transforms.ToTensor(),
])

test_transform = transforms.ToTensor()

mnist_train_t = torchvision.datasets.MNIST("./data", train=True, \
                                           transform=train_transform)
mnist_test_t = torchvision.datasets.MNIST("./data", train=False, \
                                          transform=test_transform)
mnist_train_loader_t = DataLoader(mnist_train_t, shuffle=True,  \
                                  batch_size=B, num_workers=5)
mnist_test_loader_t = DataLoader(mnist_test_t, batch_size=B, num_workers=5)

model_cnn_pool = nn.Sequential(
  nn.Conv2d(C, filters, 3, padding=3//2),
  nn.Tanh(),
  nn.Conv2d(filters, filters, 3, padding=3//2),
  nn.Tanh(),
  nn.Conv2d(filters, filters, 3, padding=3//2),
  nn.Tanh(),
  nn.MaxPool2d(2),
  nn.Conv2d(filters, 2*filters, 3, padding=3//2),
  nn.Tanh(),
  nn.Conv2d(2*filters, 2*filters, 3, padding=3//2),
  nn.Tanh(),
  nn.Conv2d(2*filters, 2*filters, 3, padding=3//2),
  nn.Tanh(),
  nn.MaxPool2d(2),
  nn.Flatten(),
  nn.Linear(2*filters*D//(4**2), classes),
)
loss_func = nn.CrossEntropyLoss()
cnn_results_with_pool_augmented = train_simple_network(model_cnn_pool,\
                                     loss_func, \
                                     mnist_train_loader_t, \
                                     test_loader=mnist_test_loader_t, \
                                     score_funcs={'Accuracy': \
                                     accuracy_score}, \
                                     device=device, epochs=20)

sns.lineplot(x='epoch', y='test Accuracy', \
             data=cnn_results_with_pool, label='CNN w/ Max Pooling')
sns.lineplot(x='epoch', y='test Accuracy', \
             data=cnn_results_with_pool_augmented, \
             label='CNN w/ Max Pooling + Augmentation')