# -*- coding: utf-8 -*-
"""Week04_CNN_I.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1aX9TimeMBNqSfTF-zcNYIJrC31qXguLt
"""

from google.colab import drive
drive.mount('/content/drive')

import sys
sys.path.append('/content/drive/My Drive/Colab Notebooks/Week06')

import torch
import torch.nn as nn
import torch.nn.functional as F


from torch.utils.data import Dataset, DataLoader

from tqdm.autonotebook import tqdm

import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from matplotlib.pyplot import imshow

import pandas as pd

from sklearn.metrics import accuracy_score

import time
from idlmam import *

import torchvision
from torchvision import transforms

mnist_data_train = torchvision.datasets.MNIST("./data", train=True,\
                                              download=True)
mnist_data_test = torchvision.datasets.MNIST("./data", train=False,\
download=True)

x_example, y_example = mnist_data_train[0]

type(x_example)

mnist_data_train = torchvision.datasets.MNIST("./data", train=True,\
                                        download=True, \
                                        transform=transforms.ToTensor())

mnist_data_test = torchvision.datasets.MNIST("./data", train=False,\
                                   download=True, \
                                   transform=transforms.ToTensor())

x_example, y_example = mnist_data_train[0]

print(x_example.shape)

imshow(x_example[0,:], cmap='gray')

x_as_color = torch.stack([x_example[0,:], x_example[0,:], x_example[0,:]],\
                         dim=0)
print(x_as_color.shape)



imshow(x_as_color.permute(1,2,0))

x_as_color = torch.stack([x_example[0,:], x_example[0,:], x_example[0,:]])
x_as_color[0,:] = 0 #No Red.We’re leaving Green alone.
x_as_color[2,:] = 0 #No Blue
imshow(x_as_color.permute(1,2,0))

x1, x2, x3 = mnist_data_train[0], mnist_data_train[1], \
mnist_data_train[2] #Grabs 3 images

x1, x2, x3 = x1[0], x2[0], x3[0] #Drops the labels

x_as_color = torch.stack([x1[0,:], x2[0,:], x3[0,:]], dim=0)

imshow(x_as_color.permute(1,2,0))

rand_order = torch.randperm(x_example.shape[1] * x_example.shape[2])
x_shuffled = x_example.view(-1)[rand_order].view(x_example.shape)

imshow(x_shuffled[0,:], cmap='gray')

from scipy.signal import convolve
img_indx = 58
img = mnist_data_train[img_indx][0][0,:]

plt.imshow(img, vmin=0, vmax=1, cmap='gray')

blur_filter = np.asarray([[1,1,1],
                          [1,1,1],
                          [1,1,1]
                                ])/9.0
blurry_img = convolve(img, blur_filter)
plt.imshow(blurry_img, vmin=0, vmax=1, cmap='gray')
plt.show()

edge_filter = np.asarray([[-1,-1,-1],
                          [-1, 8,-1],
                          [-1,-1,-1]
                                   ])
edge_img = convolve(img, edge_filter)

plt.imshow(edge_img, vmin=0, vmax=1, cmap='gray')
plt.show()

h_edge_filter = np.asarray([[-1,-1,-1],
                            [0, 0,0],
                            [1, 1, 1]
                                    ])
h_edge_img = convolve(img, h_edge_filter)

plt.imshow(h_edge_img, vmin=0, vmax=1, cmap='gray')
plt.show()

if torch.cuda.is_available():
  device = torch.device("cuda")
else:
  device = torch.device("cpu")

B = 32
mnist_train_loader = DataLoader(mnist_data_train, batch_size=B, shuffle=True)
mnist_test_loader = DataLoader(mnist_data_test, batch_size=B)

#We use the number of values in the input
#to help determine the size of subsequent layers:
#28 * 28 images.
D = 28*28

#No of channels in input
C = 1

classes = 10

filters = 16

#Size of Kernel
K = 3

#For comparison, let’s define a linear model
#of similar complexity.
model_linear = nn.Sequential(
  nn.Flatten(), # (B, C, W, H) -> (B, C*W*H) = (B,D)
  nn.Linear(D, 256),
  nn.Tanh(),
  nn.Linear(256, classes),
)

#Simple convolutional network.
#Conv2d follows the pattern
#Conv2d(No of input channels,
#filtersoutput-channels, filter-size).

model_cnn = nn.Sequential(
  nn.Conv2d(C, filters, K, padding=K//2), # x convolve with G
  #Activation functions
  #work on any size tensor.
  nn.Tanh(),
  #Converts from (B, C, W, H) ->(B, D)
  #so we can use a Linear layer.
  nn.Flatten(),
  nn.Linear(filters*D, classes),
)

loss_func = nn.CrossEntropyLoss()

cnn_results = train_simple_network(model_cnn, loss_func,\
                      mnist_train_loader, test_loader=mnist_test_loader,\
                        score_funcs={'Accuracy': accuracy_score}, \
                        device=device, epochs=20)

fc_results = train_simple_network(model_linear, loss_func,\
                       mnist_train_loader, test_loader=mnist_test_loader,\
                       score_funcs={'Accuracy': accuracy_score}, \
                       device=device, epochs=20)

sns.lineplot(x='epoch', y='test Accuracy', data=cnn_results, label='CNN')
sns.lineplot(x='epoch', y='test Accuracy', data=fc_results,
label='Fully Connected')

#=========================================================
#=========================================================
#=========================================================
#=========================================================
#=========================================================
#=========================================================
#=========================================================
#=========================================================
#=========================================================
#=========================================================
#=========================================================

# -*- coding: utf-8 -*-
"""Week04_CNN_I.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1aX9TimeMBNqSfTF-zcNYIJrC31qXguLt
"""

# --- SETUP AND IMPORTS ---
from google.colab import drive
drive.mount('/content/drive')

import sys
# Add path to import custom modules (idlmam.py)
sys.path.append('/content/drive/My Drive/Colab Notebooks/Week06')

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
from tqdm.autonotebook import tqdm
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from matplotlib.pyplot import imshow
import pandas as pd
from sklearn.metrics import accuracy_score
import time
from idlmam import * # Imports helper functions like train_simple_network

import torchvision
from torchvision import transforms

# --- LOADING MNIST DATA ---
# Load MNIST dataset. These are 28x28 grayscale images of handwritten digits.
# This first load downloads the data but keeps it as PIL Images (Python Imaging Library).
mnist_data_train = torchvision.datasets.MNIST("./data", train=True,\
                                              download=True)
mnist_data_test = torchvision.datasets.MNIST("./data", train=False,\
                                             download=True)

# Access a single sample
x_example, y_example = mnist_data_train[0]
# Check type - it's a PIL Image, not a Tensor yet.
type(x_example)

# --- LOADING AS TENSORS ---
# Reload dataset with transforms.ToTensor().
# This converts images to PyTorch Tensors (C, H, W) with values in range [0, 1].
mnist_data_train = torchvision.datasets.MNIST("./data", train=True,\
                                        download=True, \
                                        transform=transforms.ToTensor())

mnist_data_test = torchvision.datasets.MNIST("./data", train=False,\
                                   download=True, \
                                   transform=transforms.ToTensor())

# Access sample again
x_example, y_example = mnist_data_train[0]

# Check shape: (1, 28, 28). This means 1 Channel (Grayscale), 28 Height, 28 Width.
print(x_example.shape)

# --- VISUALIZING TENSORS ---
# To visualize with matplotlib, we generally need (H, W) or (H, W, C).
# Here we take the first channel (index 0) to visualize the grayscale image.
imshow(x_example[0,:], cmap='gray')

# --- MANIPULATING CHANNELS (GRAYSCALE TO RGB) ---
# Stack 3 copies of the grayscale image to simulate an RGB image.
# Shape becomes (3, 28, 28).
x_as_color = torch.stack([x_example[0,:], x_example[0,:], x_example[0,:]],\
                          dim=0)
print(x_as_color.shape)

# Permute dimensions for plotting.
# PyTorch uses (C, H, W). Matplotlib expects (H, W, C).
# permute(1, 2, 0) changes order from (0,1,2) to (1,2,0) -> (H, W, C).
imshow(x_as_color.permute(1,2,0))

# --- MODIFYING CHANNELS ---
# Reset x_as_color
x_as_color = torch.stack([x_example[0,:], x_example[0,:], x_example[0,:]])

# Zero out the Red (channel 0) and Blue (channel 2) channels.
# Only Green (channel 1) remains.
x_as_color[0,:] = 0 # No Red.
x_as_color[2,:] = 0 # No Blue.
imshow(x_as_color.permute(1,2,0)) # Result should be a green digit.

# --- STACKING DIFFERENT IMAGES ---
# Grab 3 different images from the dataset
x1, x2, x3 = mnist_data_train[0], mnist_data_train[1], \
             mnist_data_train[2]

# Extract the image tensors (drop labels)
x1, x2, x3 = x1[0], x2[0], x3[0]

# Stack them into RGB channels:
# R = x1 (digit 5), G = x2 (digit 0), B = x3 (digit 4)
x_as_color = torch.stack([x1[0,:], x2[0,:], x3[0,:]], dim=0)

# Visualize the composite image. Overlapping regions blend colors.
imshow(x_as_color.permute(1,2,0))

# --- STRUCTURE MATTERS ---
# Demonstrate that shuffling pixels destroys the information.
# Flatten, shuffle randomly, and reshape back to (1, 28, 28).
rand_order = torch.randperm(x_example.shape[1] * x_example.shape[2])
x_shuffled = x_example.view(-1)[rand_order].view(x_example.shape)

imshow(x_shuffled[0,:], cmap='gray') # Result looks like noise.

# --- MANUAL CONVOLUTION (IMAGE PROCESSING) ---
from scipy.signal import convolve
img_indx = 58
img = mnist_data_train[img_indx][0][0,:] # Extract single 2D image (28, 28)

plt.imshow(img, vmin=0, vmax=1, cmap='gray')

# 1. BLUR FILTER (Averaging)
# A 3x3 filter where all values are 1/9.
# This averages each pixel with its neighbors, smoothing the image.
blur_filter = np.asarray([[1,1,1],
                          [1,1,1],
                          [1,1,1]
                                ])/9.0
blurry_img = convolve(img, blur_filter)
plt.imshow(blurry_img, vmin=0, vmax=1, cmap='gray')
plt.show()

# 2. EDGE DETECTION FILTER
# A filter that highlights changes in intensity (edges).
# Center is positive, neighbors are negative. Sum is 0 (constant regions become black).
edge_filter = np.asarray([[-1,-1,-1],
                          [-1, 8,-1],
                          [-1,-1,-1]
                                  ])
edge_img = convolve(img, edge_filter)

plt.imshow(edge_img, vmin=0, vmax=1, cmap='gray')
plt.show()

# 3. HORIZONTAL EDGE FILTER
# Detects horizontal lines. Top row negative, bottom row positive.
h_edge_filter = np.asarray([[-1,-1,-1],
                            [0, 0,0],
                            [1, 1, 1]
                                    ])
h_edge_img = convolve(img, h_edge_filter)

plt.imshow(h_edge_img, vmin=0, vmax=1, cmap='gray')
plt.show()

# --- BUILDING A CNN IN PYTORCH ---

# Setup Device
if torch.cuda.is_available():
  device = torch.device("cuda")
else:
  device = torch.device("cpu")

# Setup DataLoaders
B = 32
mnist_train_loader = DataLoader(mnist_data_train, batch_size=B, shuffle=True)
mnist_test_loader = DataLoader(mnist_data_test, batch_size=B)

# Define Hyperparameters
D = 28*28 # Flattened input size (for Linear model)
C = 1     # Input Channels (Grayscale)
classes = 10 # Output classes (digits 0-9)
filters = 16 # Number of filters in Conv layer
K = 3     # Kernel size (3x3)

# MODEL 1: LINEAR MODEL (MLP)
# Requires flattening the image first, losing spatial structure.
model_linear = nn.Sequential(
  nn.Flatten(), # Flatten (B, 1, 28, 28) -> (B, 784)
  nn.Linear(D, 256),
  nn.Tanh(),
  nn.Linear(256, classes),
)

# MODEL 2: CONVOLUTIONAL NEURAL NETWORK (CNN)
# Processes the image directly using convolution.
model_cnn = nn.Sequential(
  # Conv2d Layer:
  # Input: (B, 1, 28, 28) -> Output: (B, 16, 28, 28)
  # Padding=K//2 (padding=1 for K=3) ensures output size = input size.
  nn.Conv2d(C, filters, K, padding=K//2), 
  
  nn.Tanh(), # Activation
  
  # Flatten: (B, 16, 28, 28) -> (B, 16*28*28)
  # We flatten AFTER convolution to pass to the final Linear classifier.
  nn.Flatten(),
  
  # Linear Layer: Input size is Filters * Height * Width
  nn.Linear(filters*D, classes),
)

loss_func = nn.CrossEntropyLoss()

# --- TRAINING COMPARISON ---

# Train CNN
cnn_results = train_simple_network(model_cnn, loss_func,\
                       mnist_train_loader, test_loader=mnist_test_loader,\
                         score_funcs={'Accuracy': accuracy_score}, \
                         device=device, epochs=20)

# Train Linear Model (MLP)
fc_results = train_simple_network(model_linear, loss_func,\
                        mnist_train_loader, test_loader=mnist_test_loader,\
                        score_funcs={'Accuracy': accuracy_score}, \
                        device=device, epochs=20)

# Plot Results
# CNN typically converges faster and reaches higher accuracy on image data.
sns.lineplot(x='epoch', y='test Accuracy', data=cnn_results, label='CNN')
sns.lineplot(x='epoch', y='test Accuracy', data=fc_results,
label='Fully Connected')