# -*- coding: utf-8 -*-
"""Week04_CNN_I.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1aX9TimeMBNqSfTF-zcNYIJrC31qXguLt
"""

from google.colab import drive
drive.mount('/content/drive')

import sys
sys.path.append('/content/drive/My Drive/Colab Notebooks/Week06')

import torch
import torch.nn as nn
import torch.nn.functional as F


from torch.utils.data import Dataset, DataLoader

from tqdm.autonotebook import tqdm

import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from matplotlib.pyplot import imshow

import pandas as pd

from sklearn.metrics import accuracy_score

import time
from idlmam import *

import torchvision
from torchvision import transforms

mnist_data_train = torchvision.datasets.MNIST("./data", train=True,\
                                              download=True)
mnist_data_test = torchvision.datasets.MNIST("./data", train=False,\
download=True)

x_example, y_example = mnist_data_train[0]

type(x_example)

mnist_data_train = torchvision.datasets.MNIST("./data", train=True,\
                                        download=True, \
                                        transform=transforms.ToTensor())

mnist_data_test = torchvision.datasets.MNIST("./data", train=False,\
                                   download=True, \
                                   transform=transforms.ToTensor())

x_example, y_example = mnist_data_train[0]

print(x_example.shape)

imshow(x_example[0,:], cmap='gray')

x_as_color = torch.stack([x_example[0,:], x_example[0,:], x_example[0,:]],\
                         dim=0)
print(x_as_color.shape)



imshow(x_as_color.permute(1,2,0))

x_as_color = torch.stack([x_example[0,:], x_example[0,:], x_example[0,:]])
x_as_color[0,:] = 0 #No Red.We’re leaving Green alone.
x_as_color[2,:] = 0 #No Blue
imshow(x_as_color.permute(1,2,0))

x1, x2, x3 = mnist_data_train[0], mnist_data_train[1], \
mnist_data_train[2] #Grabs 3 images

x1, x2, x3 = x1[0], x2[0], x3[0] #Drops the labels

x_as_color = torch.stack([x1[0,:], x2[0,:], x3[0,:]], dim=0)

imshow(x_as_color.permute(1,2,0))

rand_order = torch.randperm(x_example.shape[1] * x_example.shape[2])
x_shuffled = x_example.view(-1)[rand_order].view(x_example.shape)

imshow(x_shuffled[0,:], cmap='gray')

from scipy.signal import convolve
img_indx = 58
img = mnist_data_train[img_indx][0][0,:]

plt.imshow(img, vmin=0, vmax=1, cmap='gray')

blur_filter = np.asarray([[1,1,1],
                          [1,1,1],
                          [1,1,1]
                                ])/9.0
blurry_img = convolve(img, blur_filter)
plt.imshow(blurry_img, vmin=0, vmax=1, cmap='gray')
plt.show()

edge_filter = np.asarray([[-1,-1,-1],
                          [-1, 8,-1],
                          [-1,-1,-1]
                                   ])
edge_img = convolve(img, edge_filter)

plt.imshow(edge_img, vmin=0, vmax=1, cmap='gray')
plt.show()

h_edge_filter = np.asarray([[-1,-1,-1],
                            [0, 0,0],
                            [1, 1, 1]
                                    ])
h_edge_img = convolve(img, h_edge_filter)

plt.imshow(h_edge_img, vmin=0, vmax=1, cmap='gray')
plt.show()

if torch.cuda.is_available():
  device = torch.device("cuda")
else:
  device = torch.device("cpu")

B = 32
mnist_train_loader = DataLoader(mnist_data_train, batch_size=B, shuffle=True)
mnist_test_loader = DataLoader(mnist_data_test, batch_size=B)

#We use the number of values in the input
#to help determine the size of subsequent layers:
#28 * 28 images.
D = 28*28

#No of channels in input
C = 1

classes = 10

filters = 16

#Size of Kernel
K = 3

#For comparison, let’s define a linear model
#of similar complexity.
model_linear = nn.Sequential(
  nn.Flatten(), # (B, C, W, H) -> (B, C*W*H) = (B,D)
  nn.Linear(D, 256),
  nn.Tanh(),
  nn.Linear(256, classes),
)

#Simple convolutional network.
#Conv2d follows the pattern
#Conv2d(No of input channels,
#filtersoutput-channels, filter-size).

model_cnn = nn.Sequential(
  nn.Conv2d(C, filters, K, padding=K//2), # x convolve with G
  #Activation functions
  #work on any size tensor.
  nn.Tanh(),
  #Converts from (B, C, W, H) ->(B, D)
  #so we can use a Linear layer.
  nn.Flatten(),
  nn.Linear(filters*D, classes),
)

loss_func = nn.CrossEntropyLoss()

cnn_results = train_simple_network(model_cnn, loss_func,\
                      mnist_train_loader, test_loader=mnist_test_loader,\
                        score_funcs={'Accuracy': accuracy_score}, \
                        device=device, epochs=20)

fc_results = train_simple_network(model_linear, loss_func,\
                       mnist_train_loader, test_loader=mnist_test_loader,\
                       score_funcs={'Accuracy': accuracy_score}, \
                       device=device, epochs=20)

sns.lineplot(x='epoch', y='test Accuracy', data=cnn_results, label='CNN')
sns.lineplot(x='epoch', y='test Accuracy', data=fc_results,
label='Fully Connected')